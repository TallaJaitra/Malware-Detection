# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S8LaGIVBqSWWS3_UqHMOtzWHfYjDU-Oo
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import pickle
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
plt.style.use('ggplot')

data = pd.read_csv('/content/dataset_malwares.csv')

data.head()

data.info()

used_data = data.drop(['Name', 'Machine', 'TimeDateStamp', 'Malware'], axis=1)

plt.figure(figsize=(8, 6))
ax=sns.countplot(data['Malware'])
ax.set_xticklabels(['Benign', 'Malware'])

features = ['MajorSubsystemVersion', 'MajorLinkerVersion', 'SizeOfCode', 'SizeOfImage', 'SizeOfHeaders', 'SizeOfInitializedData',
           'SizeOfUninitializedData', 'SizeOfStackReserve', 'SizeOfHeapReserve',
            'NumberOfSymbols', 'SectionMaxChar']
i=1

for feature in features:
    plt.figure(figsize=(10, 15))
    ax1 = plt.subplot(len(features), 2, i)
    sns.distplot(data[data['Malware']==1][feature], ax=ax1, kde_kws={'bw': 0.1})
    ax1.set_title(f'Malware', fontsize=10)
    ax2 = plt.subplot(len(features), 2, i+1)
    sns.distplot(data[data['Malware']==0][feature], ax=ax2, kde_kws={'bw': 0.1})
    ax2.set_title(f'Benign', fontsize=10)
    i= i+2

X_train, X_test, y_train, y_test = train_test_split(used_data, data['Malware'], test_size=0.2, random_state=0)

print(f'Number of used features is {X_train.shape[1]}')

rfc = RandomForestClassifier(n_estimators=100, random_state=0,
                         oob_score = True,
                         max_depth = 16)
rfc.fit(X_train, y_train)

y_pred = rfc.predict(X_test)

print(classification_report(y_test, y_pred, target_names=['Benign', 'Malware']))

ax=sns.heatmap(confusion_matrix(y_pred, y_test), annot=True, fmt="d", cmap=plt.cm.Blues, cbar=False)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')

pkl_filename = "rf_model.pkl"
with open(pkl_filename, 'wb') as file:
    pickle.dump(rfc, file)

importance = rfc.feature_importances_
importance_dict = {used_data.columns.values[i]: importance[i] for i in range (len(importance))}
sorted_dict = {k: v for k, v in sorted(importance_dict.items(), key=lambda item: item[1])}
plt.figure(figsize=(10, 20))
sns.barplot(y=list(sorted_dict.keys())[::-1], x=list(sorted_dict.values())[::-1], palette='mako')
plt.title('Features importance')

"""### Overview

Malware detection using machine learning involves developing models that can identify malicious software based on its features and behaviors. Traditional methods rely on signature-based detection, which can struggle against new and evolving threats. Machine learning models can generalize from known data to detect previously unseen malware.

### Steps in a Machine Learning-Based Malware Detection Project

1. **Data Collection**:
   - **Sources**: Gather datasets of both malware and benign software. Public repositories like VirusTotal, MalwareBazaar, and the Microsoft Malware Classification Challenge dataset can be useful.
   - **Labels**: Ensure that each sample is accurately labeled as either benign or malicious.

2. **Feature Extraction**:
   - **Static Analysis**: Extract features without executing the software, such as opcode sequences, byte sequences, file metadata (e.g., file size, hash values), and strings within the executable.
   - **Dynamic Analysis**: Execute the software in a controlled environment to observe behaviors like API calls, network traffic, file system changes, and registry modifications.
   - **Hybrid Analysis**: Combine static and dynamic features for a more comprehensive feature set.

3. **Feature Engineering**:
   - **Preprocessing**: Normalize data, handle missing values, and encode categorical variables.
   - **Dimensionality Reduction**: Techniques like PCA (Principal Component Analysis) can be used to reduce the feature space, improving model performance and training speed.
   - **Feature Selection**: Choose the most relevant features using methods like correlation analysis, mutual information, or feature importance from tree-based models.

4. **Model Selection**:
   - **Algorithms**: Common algorithms include Decision Trees, Random Forests, Gradient Boosting Machines, Support Vector Machines, and Neural Networks.
   - **Ensemble Methods**: Combine multiple models to improve performance and robustness.

5. **Model Training**:
   - **Train/Test Split**: Divide the dataset into training and testing sets to evaluate the model's performance.
   - **Cross-Validation**: Use k-fold cross-validation to ensure the model generalizes well to unseen data.

6. **Model Evaluation**:
   - **Metrics**: Evaluate the model using metrics like accuracy, precision, recall, F1-score, and AUC-ROC curve.
   - **Confusion Matrix**: Analyze the confusion matrix to understand the types of errors the model makes.

7. **Model Optimization**:
   - **Hyperparameter Tuning**: Use techniques like Grid Search or Random Search to find the best hyperparameters for the model.
   - **Regularization**: Apply regularization techniques to prevent overfitting.

8. **Deployment**:
   - **Integration**: Integrate the model into a larger system for real-time malware detection.
   - **Monitoring**: Continuously monitor the model's performance in production and retrain with new data as necessary.

9. **Updating and Maintenance**:
   - **Retraining**: Periodically retrain the model with new data to keep it up-to-date with evolving threats.
   - **Feedback Loop**: Incorporate feedback from false positives and false negatives to improve the model.

### Example Workflow

1. **Data Collection**:
   - Download malware samples from VirusTotal.
   - Collect benign software samples from trusted sources.

2. **Feature Extraction**:
   - Perform static analysis to extract byte sequences and opcode frequencies.
   - Conduct dynamic analysis in a sandbox environment to record API calls and network activity.

3. **Feature Engineering**:
   - Normalize byte sequence lengths and standardize API call counts.
   - Use PCA to reduce the dimensionality of the feature set.

4. **Model Selection and Training**:
   - Train a Random Forest model on the feature set.
   - Perform 10-fold cross-validation to validate the model.

5. **Evaluation and Optimization**:
   - Evaluate the model using the F1-score and AUC-ROC curve.
   - Tune hyperparameters using Grid Search.

6. **Deployment**:
   - Deploy the model as a REST API for integration with existing security infrastructure.
   - Set up a monitoring system to track model performance and detect drifts.

### Tools and Libraries

- **Data Collection**: `requests`, `BeautifulSoup` for web scraping.
- **Static Analysis**: `pefile`, `capstone`.
- **Dynamic Analysis**: Cuckoo Sandbox, `pyshark` for packet capture analysis.
- **Feature Engineering**: `pandas`, `numpy`, `scikit-learn`.
- **Model Training**: `scikit-learn`, `xgboost`, `tensorflow`, `keras`.
- **Evaluation**: `scikit-learn.metrics`.
- **Deployment**: `flask`, `django`, `fastapi`.

### Challenges

- **Evolving Threats**: Malware constantly evolves, making it essential to regularly update the model.
- **Imbalanced Data**: Malware datasets are often imbalanced, requiring techniques like oversampling, undersampling, or synthetic data generation (SMOTE).
- **Feature Selection**: Identifying the most relevant features is crucial for model performance.
- **False Positives/Negatives**: Minimizing false positives (benign software flagged as malware) and false negatives (malware not detected) is critical for practical use.

By leveraging machine learning, malware detection systems can become more adaptable and effective against sophisticated threats, offering a robust solution for cybersecurity challenges.
"""